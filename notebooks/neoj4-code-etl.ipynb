{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [JarAnalyzer](http://www.kirkk.com/main/Main/JarAnalyzer)\n",
    "\n",
    "**Number of Classes**  \n",
    "The number of concrete and abstract classes (and interfaces) in the jar is an indicator of the extensibility of the jar.\n",
    "\n",
    "**Number of Packages**  \n",
    "The number of packages in the jar.\n",
    "\n",
    "**Level**  \n",
    "The Level represents where in the hierarchy a jar file lives. Level 1 jars are at the bottom. Level 2 depend on at least one Level 1. Level 3 depend on at least one Level 2. The Level of the jar, used in conjunction with Instability, gives an indication of the jar's resilience to change.\n",
    "\n",
    "**Afferent Couplings**  \n",
    "The number of other jars that depend upon classes within the jar is an indicator of the jar's responsibility.\n",
    "\n",
    "**Efferent Couplings**  \n",
    "The number of other jars that the classes in the jar depend upon is an indicator of the jar's independence.\n",
    "\n",
    "**Abstractness**  \n",
    "The ratio of the number of abstract classes (and interfaces) in the analyzed jar to the total number of classes in the analyzed jar.\n",
    "\n",
    "The range for this metric is 0 to 1, with A=0 indicating a completely concrete jar and A=1 indicating a completely abstract jar.\n",
    "\n",
    "**Instability**  \n",
    "The ratio of efferent coupling (Ce) to total coupling (Ce / (Ce + Ca)). This metric is an indicator of the jar's resilience to change.\n",
    "\n",
    "The range for this metric is 0 to 1, with I=0 indicating a completely stable jar and I=1 indicating a completely instable jar.\n",
    "\n",
    "**Distance**  \n",
    "The perpendicular distance of a jar from the idealized line A + I = 1. This metric is an indicator of the jar's balance between abstractness and stability.\n",
    "\n",
    "A jar squarely on the main sequence is optimally balanced with respect to its abstractness and stability. Ideal jars are either completely abstract and stable (x=0, y=1) or completely concrete and instable (x=1, y=0).\n",
    "\n",
    "The range for this metric is 0 to 1, with D=0 indicating a jar that is coincident with the main sequence and D=1 indicating a jar that is as far from the main sequence as possible.\n",
    "\n",
    "**Unresolved Packages**  \n",
    "Packages not found in any of the jars analyzed. These can be filtered from output by specifying the packages to exlude in the Filter.properties file. Conversely, you can include jars containing these packages in the directory being analyzed.\n",
    "\n",
    "These packages are excluded from all calculations and adding the jars containing these packages will result in modified metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# add project root directory to python path to enable import of saapy\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keyring\n",
    "from neo4j.v1 import GraphDatabase, basic_auth\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jar_properties(jar):\n",
    "    jar_name = jar.get(\"name\")\n",
    "    stats = jar.find(\"./Summary/Statistics\")\n",
    "    metrics = jar.find(\"./Summary/Metrics\")\n",
    "    class_count = int(stats.find(\"./ClassCount\").text)\n",
    "    abstract_class_count = int(stats.find(\"./AbstractClassCount\").text)\n",
    "    package_count = int(stats.find(\"./PackageCount\").text)\n",
    "    abstractness = float(metrics.find(\"./Abstractness\").text)\n",
    "    efferent = int(metrics.find(\"./Efferent\").text)\n",
    "    afferent = int(metrics.find(\"./Afferent\").text)\n",
    "    instability = float(metrics.find(\"./Instability\").text)\n",
    "    distance = float(metrics.find(\"./Distance\").text)\n",
    "    node_props = {\n",
    "        \"name\": jar_name,\n",
    "        \"class_count\": class_count,\n",
    "        \"abstract_class_count\": abstract_class_count,\n",
    "        \"package_count\": package_count,\n",
    "        \"abstractness\": abstractness,\n",
    "        \"efferent\": efferent,\n",
    "        \"afferent\": afferent,\n",
    "        \"instability\": instability,\n",
    "        \"distance\": distance\n",
    "    }\n",
    "    return node_props\n",
    "\n",
    "def merge_jar_node(tx, jar):\n",
    "    node_props = jar_properties(jar)\n",
    "    jar_name = node_props[\"name\"]\n",
    "    query = \"\"\"\n",
    "    MERGE (jar:JarFile {\n",
    "        name: {name},\n",
    "        class_count: {class_count},\n",
    "        abstract_class_count: {abstract_class_count},\n",
    "        package_count: {package_count},\n",
    "        abstractness: {abstractness},\n",
    "        efferent: {efferent},\n",
    "        afferent: {afferent},\n",
    "        instability: {instability},\n",
    "        distance: {distance}\n",
    "    })\n",
    "    \"\"\"\n",
    "    result = tx.run(query, node_props)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_package(tx, jar_name, package_name):\n",
    "    query = \"\"\"\n",
    "    MATCH (jar:JarFile {name: {jar_name}})\n",
    "    MERGE (package:JavaPackage {\n",
    "        name: {package_name}\n",
    "    })\n",
    "    MERGE (jar)-[r:CONTAINS]->(package)\n",
    "    \"\"\"\n",
    "    result = tx.run(query, {\"jar_name\": jar_name, \"package_name\": package_name})\n",
    "    return result\n",
    "\n",
    "def add_unresolved_dependency(tx, jar_name, package_name):\n",
    "    query = \"\"\"\n",
    "    MATCH (jar:JarFile {name: {jar_name}})\n",
    "    MERGE (package:JavaPackage {\n",
    "        name: {package_name}\n",
    "    })\n",
    "    MERGE\n",
    "    (jar)-[r:DEPENDS_UNRESOLVED]->(package)\n",
    "    \"\"\"\n",
    "    result = tx.run(query, {\"jar_name\": jar_name, \"package_name\": package_name})\n",
    "    return result\n",
    "\n",
    "def add_packages(tx, jar):\n",
    "    jar_name = jar.get(\"name\")\n",
    "    for package in jar.findall(\"./Summary/Packages/Package\"):\n",
    "        package_name = package.text\n",
    "        add_package(tx, jar_name, package_name)\n",
    "    for package in jar.findall(\"./Summary/UnresolvedDependencies/Package\"):\n",
    "        package_name = package.text\n",
    "        add_unresolved_dependency(tx, jar_name, package_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_jar_dependencies(tx, jar):\n",
    "    jar_name = jar.get(\"name\")\n",
    "    out_deps = jar.findall(\"./Summary/OutgoingDependencies/Jar\")\n",
    "    for out_jar in out_deps:\n",
    "        out_jar_name = out_jar.text\n",
    "        query = \"\"\"\n",
    "        MATCH (jar:JarFile {name: {jar_name}})\n",
    "        MATCH (out_jar:JarFile {name: {out_jar_name}})\n",
    "        MERGE\n",
    "        (jar)-[r:DEPENDS]->(out_jar)\n",
    "        \"\"\"\n",
    "        tx.run(query, {\"jar_name\": jar_name, \"out_jar_name\": out_jar_name})\n",
    "    in_deps = jar.findall(\"./Summary/IncomingDependencies/Jar\")\n",
    "    for in_jar in in_deps:\n",
    "        in_jar_name = in_jar.text\n",
    "        query = \"\"\"\n",
    "        MATCH (jar:JarFile {name: {jar_name}})\n",
    "        MATCH (in_jar:JarFile {name: {in_jar_name}})\n",
    "        MERGE\n",
    "        (jar)-[r:DEPENDED_BY]->(in_jar)\n",
    "        \"\"\"\n",
    "        tx.run(query, {\"jar_name\": jar_name, \"in_jar_name\": in_jar_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_jar_cycles(tx, jar):\n",
    "    jar_name = jar.get(\"name\")\n",
    "    cycles = jar.findall(\"./Summary/Cycles/Cycle\")\n",
    "    for cycle_jar in cycles:\n",
    "        cycle_jar_name = cycle_jar.text\n",
    "        query = \"\"\"\n",
    "        MATCH (jar:JarFile {name: {jar_name}})\n",
    "        MATCH (cycle_jar:JarFile {name: {cycle_jar_name}})\n",
    "        MERGE\n",
    "        (jar)-[r:CYCLE]->(cycle_jar)\n",
    "        \"\"\"\n",
    "        tx.run(query, {\"jar_name\": jar_name, \"cycle_jar_name\": cycle_jar_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neo4j_service = \"test_neo4j\"\n",
    "neo4j_user = \"neo4j\"\n",
    "neo4j_password = keyring.get_password(neo4j_service, neo4j_user)\n",
    "neo4j_url = \"bolt://localhost\"\n",
    "driver = GraphDatabase.driver(neo4j_url, auth=basic_auth(neo4j_user, neo4j_password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# produced with JarAnalyzer 1.2\n",
    "idempiere_jar_deps_xml = \"../data/idempiere/idempiere-jar-deps-jaranalyzer.xml\"\n",
    "deps_tree = ET.parse(idempiere_jar_deps_xml)\n",
    "root = deps_tree.getroot()\n",
    "jars = root.findall(\"./Jars/Jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neo4j_session = driver.session()\n",
    "tx = neo4j_session.begin_transaction()\n",
    "try:\n",
    "    for jar in jars:\n",
    "        merge_jar_node(tx, jar)\n",
    "        add_packages(tx, jar)\n",
    "        merge_jar_dependencies(tx, jar)\n",
    "        merge_jar_cycles(tx, jar)\n",
    "except:\n",
    "    tx.rollback()\n",
    "else:\n",
    "    tx.commit()\n",
    "finally:\n",
    "    neo4j_session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from saapy import scitools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "udb = scitools.safe_open_understand(\"../data/idempiere/idempiere-fork1-development.udb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def store_couples(udb, run_query):\n",
    "    java_files = udb.ents(\"Java File\")\n",
    "    for fent in java_files:\n",
    "        pfent = fent.refs(\"Define\", \"Package\")[0].ent()\n",
    "        file_query = \"\"\"\n",
    "        MERGE (file:JavaFile {name: {file_name}})\n",
    "        MERGE (package:JavaPackage {name: {package_name}})\n",
    "        MERGE (file)-[r:DEFINES]->(package)\n",
    "        \"\"\"\n",
    "        run_query(file_query, {\"file_name\": fent.relname(), \"package_name\": pfent.longname()})\n",
    "        fmetrics = fent.metric([\"CountLineCode\", \"SumCyclomaticStrict\"])\n",
    "        set_file_metrics_query = \"\"\"\n",
    "        MATCH (file: JavaFile {name: {file_name}})\n",
    "        SET file.count_line_code = {count_line_code},\n",
    "            file.sum_cyclomatic_strict = {sum_cyclomatic_strict}\n",
    "        \"\"\"\n",
    "        run_query(set_file_metrics_query, {\n",
    "                \"file_name\": fent.relname(), \n",
    "                \"count_line_code\": fmetrics[\"CountLineCode\"],\n",
    "                \"sum_cyclomatic_strict\": fmetrics[\"SumCyclomaticStrict\"]})\n",
    "        for crel in fent.refs(\"Define\", \"Class, Interface\"):\n",
    "            cent = crel.ent()\n",
    "            class_query = \"\"\"\n",
    "            MATCH (file:JavaFile {name: {file_name}})\n",
    "            MATCH (package:JavaPackage {name: {package_name}})\n",
    "            MERGE (class:JavaClass {name: {class_name}})\n",
    "            MERGE (file)-[r:DEFINES]->(class)\n",
    "            MERGE (package)-[r1:CONTAINS]->(class)\n",
    "            \"\"\"\n",
    "            run_query(class_query, {\n",
    "                    \"file_name\": fent.relname(),\n",
    "                    \"package_name\": pfent.longname(),\n",
    "                    \"class_name\": cent.longname()})\n",
    "            for cprel in cent.refs(\"Couple\"):\n",
    "                cpent = cprel.ent()\n",
    "                pent = cpent.parent()\n",
    "                while pent.parent() is not None and pent.kindname() != \"File\":\n",
    "                    pent = pent.parent()\n",
    "                package_ent = pent.refs(\"Define\", \"Package\")[0].ent()\n",
    "                if package_ent.longname() == \"java.lang\":\n",
    "                    continue\n",
    "                run_query(file_query, {\"file_name\": pent.relname(), \"package_name\": package_ent.longname()})\n",
    "                run_query(class_query, {\n",
    "                        \"file_name\": pent.relname(),\n",
    "                        \"package_name\": package_ent.longname(),\n",
    "                        \"class_name\": cpent.longname()})\n",
    "                couple_query = \"\"\"\n",
    "                MATCH (from_class:JavaClass {name: {from_class_name}})\n",
    "                MATCH (to_class:JavaClass {name: {to_class_name}})\n",
    "                MERGE (from_class)-[r:COUPLES]->(to_class)\n",
    "                \"\"\"\n",
    "                run_query(couple_query, {\"from_class_name\": cent.longname(), \"to_class_name\": cpent.longname()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def run_query(tx, query, args):\n",
    "    return tx.run(query, args)\n",
    "\n",
    "class DryRunTx:\n",
    "    def __init__(self):\n",
    "        self.runs = []\n",
    "    def run(self, query, args):\n",
    "        self.runs.append((query, args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_in_transaction(batch_job, dry=False):\n",
    "    if dry:\n",
    "        tx = DryRunTx()\n",
    "        dry_run = partial(run_query, tx)\n",
    "        batch_job(dry_run)\n",
    "        return tx.runs\n",
    "    else:\n",
    "        neo4j_session = driver.session()\n",
    "        tx = neo4j_session.begin_transaction()\n",
    "        neo_run = partial(run_query, tx)\n",
    "        try:\n",
    "            batch_job(neo_run)\n",
    "        except:\n",
    "            tx.rollback()\n",
    "            from traceback import print_exc\n",
    "            print_exc(file=sys.stdout)\n",
    "        else:\n",
    "            tx.commit()\n",
    "        finally:\n",
    "            neo4j_session.close()\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190207\n"
     ]
    }
   ],
   "source": [
    "batch_job = partial(store_couples, udb)\n",
    "result = run_in_transaction(batch_job, dry=True)\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def recorded_batch_job(runs, run_query):\n",
    "    start_time = time.perf_counter()\n",
    "    for i, run in enumerate(runs):\n",
    "        run_query(*run)\n",
    "        if i > 0 and i % 1000 == 0:\n",
    "            next_time = time.perf_counter()\n",
    "            print(\"{0} runs processed in {1} sec\".format(i, round(next_time - start_time, 1)))\n",
    "    end_time = time.perf_counter()\n",
    "    print(\"{0} runs completed in {1} sec\".format(len(runs), round(end_time - start_time, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 runs processed in 0.0 sec\n",
      "2000 runs processed in 0.0 sec\n",
      "3000 runs processed in 0.0 sec\n",
      "4000 runs processed in 0.0 sec\n",
      "5000 runs processed in 0.0 sec\n",
      "6000 runs processed in 0.0 sec\n",
      "7000 runs processed in 0.0 sec\n",
      "8000 runs processed in 0.0 sec\n",
      "9000 runs processed in 0.0 sec\n",
      "10000 runs processed in 0.0 sec\n",
      "11000 runs processed in 0.0 sec\n",
      "12000 runs processed in 0.0 sec\n",
      "13000 runs processed in 0.0 sec\n",
      "14000 runs processed in 0.0 sec\n",
      "15000 runs processed in 0.0 sec\n",
      "16000 runs processed in 0.0 sec\n",
      "17000 runs processed in 0.0 sec\n",
      "18000 runs processed in 0.0 sec\n",
      "19000 runs processed in 0.0 sec\n",
      "20000 runs processed in 0.0 sec\n",
      "21000 runs processed in 0.0 sec\n",
      "22000 runs processed in 0.0 sec\n",
      "23000 runs processed in 0.0 sec\n",
      "24000 runs processed in 0.0 sec\n",
      "25000 runs processed in 0.0 sec\n",
      "26000 runs processed in 0.0 sec\n",
      "27000 runs processed in 0.0 sec\n",
      "28000 runs processed in 0.0 sec\n",
      "29000 runs processed in 0.0 sec\n",
      "30000 runs processed in 0.0 sec\n",
      "31000 runs processed in 0.0 sec\n",
      "32000 runs processed in 0.0 sec\n",
      "33000 runs processed in 0.0 sec\n",
      "34000 runs processed in 0.0 sec\n",
      "35000 runs processed in 0.0 sec\n",
      "36000 runs processed in 0.0 sec\n",
      "37000 runs processed in 0.0 sec\n",
      "38000 runs processed in 0.0 sec\n",
      "39000 runs processed in 0.0 sec\n",
      "40000 runs processed in 0.0 sec\n",
      "41000 runs processed in 0.0 sec\n",
      "42000 runs processed in 0.0 sec\n",
      "43000 runs processed in 0.0 sec\n",
      "44000 runs processed in 0.0 sec\n",
      "45000 runs processed in 0.0 sec\n",
      "46000 runs processed in 0.0 sec\n",
      "47000 runs processed in 0.0 sec\n",
      "48000 runs processed in 0.0 sec\n",
      "49000 runs processed in 0.0 sec\n",
      "50000 runs completed in 0.1 sec\n",
      "1000 runs processed in 0.0 sec\n",
      "2000 runs processed in 0.0 sec\n",
      "3000 runs processed in 0.0 sec\n",
      "4000 runs processed in 0.0 sec\n",
      "5000 runs processed in 0.0 sec\n",
      "6000 runs processed in 0.0 sec\n",
      "7000 runs processed in 0.0 sec\n",
      "8000 runs processed in 0.0 sec\n",
      "9000 runs processed in 0.0 sec\n",
      "10000 runs processed in 0.0 sec\n",
      "11000 runs processed in 0.0 sec\n",
      "12000 runs processed in 0.0 sec\n",
      "13000 runs processed in 0.0 sec\n",
      "14000 runs processed in 0.0 sec\n",
      "15000 runs processed in 0.0 sec\n",
      "16000 runs processed in 0.0 sec\n",
      "17000 runs processed in 0.0 sec\n",
      "18000 runs processed in 0.0 sec\n",
      "19000 runs processed in 0.0 sec\n",
      "20000 runs processed in 0.0 sec\n",
      "21000 runs processed in 0.0 sec\n",
      "22000 runs processed in 0.0 sec\n",
      "23000 runs processed in 0.0 sec\n",
      "24000 runs processed in 0.0 sec\n",
      "25000 runs processed in 0.0 sec\n",
      "26000 runs processed in 0.0 sec\n",
      "27000 runs processed in 0.0 sec\n",
      "28000 runs processed in 0.0 sec\n",
      "29000 runs processed in 0.0 sec\n",
      "30000 runs processed in 0.0 sec\n",
      "31000 runs processed in 0.0 sec\n",
      "32000 runs processed in 0.0 sec\n",
      "33000 runs processed in 0.0 sec\n",
      "34000 runs processed in 0.0 sec\n",
      "35000 runs processed in 0.0 sec\n",
      "36000 runs processed in 0.0 sec\n",
      "37000 runs processed in 0.0 sec\n",
      "38000 runs processed in 0.0 sec\n",
      "39000 runs processed in 0.0 sec\n",
      "40000 runs processed in 0.0 sec\n",
      "41000 runs processed in 0.0 sec\n",
      "42000 runs processed in 0.0 sec\n",
      "43000 runs processed in 0.0 sec\n",
      "44000 runs processed in 0.0 sec\n",
      "45000 runs processed in 0.0 sec\n",
      "46000 runs processed in 0.0 sec\n",
      "47000 runs processed in 0.0 sec\n",
      "48000 runs processed in 0.0 sec\n",
      "49000 runs processed in 0.1 sec\n",
      "50000 runs completed in 0.1 sec\n",
      "1000 runs processed in 0.0 sec\n",
      "2000 runs processed in 0.0 sec\n",
      "3000 runs processed in 0.0 sec\n",
      "4000 runs processed in 0.0 sec\n",
      "5000 runs processed in 0.0 sec\n",
      "6000 runs processed in 0.0 sec\n",
      "7000 runs processed in 0.0 sec\n",
      "8000 runs processed in 0.0 sec\n",
      "9000 runs processed in 0.0 sec\n",
      "10000 runs processed in 0.0 sec\n",
      "11000 runs processed in 0.0 sec\n",
      "12000 runs processed in 0.0 sec\n",
      "13000 runs processed in 0.0 sec\n",
      "14000 runs processed in 0.0 sec\n",
      "15000 runs processed in 0.0 sec\n",
      "16000 runs processed in 0.0 sec\n",
      "17000 runs processed in 0.0 sec\n",
      "18000 runs processed in 0.0 sec\n",
      "19000 runs processed in 0.0 sec\n",
      "20000 runs processed in 0.0 sec\n",
      "21000 runs processed in 0.0 sec\n",
      "22000 runs processed in 0.0 sec\n",
      "23000 runs processed in 0.0 sec\n",
      "24000 runs processed in 0.0 sec\n",
      "25000 runs processed in 0.0 sec\n",
      "26000 runs processed in 0.0 sec\n",
      "27000 runs processed in 0.0 sec\n",
      "28000 runs processed in 0.0 sec\n",
      "29000 runs processed in 0.0 sec\n",
      "30000 runs processed in 0.0 sec\n",
      "31000 runs processed in 0.0 sec\n",
      "32000 runs processed in 0.0 sec\n",
      "33000 runs processed in 0.0 sec\n",
      "34000 runs processed in 0.0 sec\n",
      "35000 runs processed in 0.0 sec\n",
      "36000 runs processed in 0.0 sec\n",
      "37000 runs processed in 0.0 sec\n",
      "38000 runs processed in 0.0 sec\n",
      "39000 runs processed in 0.0 sec\n",
      "40000 runs processed in 0.0 sec\n",
      "41000 runs processed in 0.0 sec\n",
      "42000 runs processed in 0.0 sec\n",
      "43000 runs processed in 0.0 sec\n",
      "44000 runs processed in 0.0 sec\n",
      "45000 runs processed in 0.0 sec\n",
      "46000 runs processed in 0.0 sec\n",
      "47000 runs processed in 0.0 sec\n",
      "48000 runs processed in 0.0 sec\n",
      "49000 runs processed in 0.0 sec\n",
      "50000 runs completed in 0.0 sec\n",
      "1000 runs processed in 0.0 sec\n",
      "2000 runs processed in 0.0 sec\n",
      "3000 runs processed in 0.0 sec\n",
      "4000 runs processed in 0.0 sec\n",
      "5000 runs processed in 0.0 sec\n",
      "6000 runs processed in 0.0 sec\n",
      "7000 runs processed in 0.0 sec\n",
      "8000 runs processed in 0.0 sec\n",
      "9000 runs processed in 0.0 sec\n",
      "10000 runs processed in 0.0 sec\n",
      "11000 runs processed in 0.0 sec\n",
      "12000 runs processed in 0.0 sec\n",
      "13000 runs processed in 0.0 sec\n",
      "14000 runs processed in 0.0 sec\n",
      "15000 runs processed in 0.0 sec\n",
      "16000 runs processed in 0.0 sec\n",
      "17000 runs processed in 0.0 sec\n",
      "18000 runs processed in 0.0 sec\n",
      "19000 runs processed in 0.0 sec\n",
      "20000 runs processed in 0.0 sec\n",
      "21000 runs processed in 0.0 sec\n",
      "22000 runs processed in 0.0 sec\n",
      "23000 runs processed in 0.0 sec\n",
      "24000 runs processed in 0.0 sec\n",
      "25000 runs processed in 0.0 sec\n",
      "26000 runs processed in 0.0 sec\n",
      "27000 runs processed in 0.0 sec\n",
      "28000 runs processed in 0.0 sec\n",
      "29000 runs processed in 0.0 sec\n",
      "30000 runs processed in 0.0 sec\n",
      "31000 runs processed in 0.0 sec\n",
      "32000 runs processed in 0.0 sec\n",
      "33000 runs processed in 0.0 sec\n",
      "34000 runs processed in 0.0 sec\n",
      "35000 runs processed in 0.0 sec\n",
      "36000 runs processed in 0.0 sec\n",
      "37000 runs processed in 0.0 sec\n",
      "38000 runs processed in 0.0 sec\n",
      "39000 runs processed in 0.0 sec\n",
      "40000 runs processed in 0.0 sec\n",
      "40207 runs completed in 0.0 sec\n"
     ]
    }
   ],
   "source": [
    "# we need to run transactions in batches < 140000 otherwise the database breaks\n",
    "chunk_size = 50000\n",
    "chunk_start = 0\n",
    "chunk_end = min(chunk_start + chunk_size, len(result))\n",
    "while chunk_start < len(result):\n",
    "    chunk = result[chunk_start:chunk_end]\n",
    "    batch_job = partial(recorded_batch_job, chunk)\n",
    "    run_in_transaction(batch_job, dry=True)\n",
    "    chunk_start = chunk_end\n",
    "    chunk_end = min(chunk_end + chunk_size, len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
